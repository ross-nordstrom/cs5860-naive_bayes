\section{Implementation}
\label{section:implementation}
A Naive Bayes classifier was implemented in Node.js \cite{node}, as a simple module with the ability to \texttt{train}
and \texttt{classify} on text, as well as some debugging interfaces such as \texttt{dump} and \texttt{restore}. This
core logic is exposed via a convenient CLI tool, which can be run locally from this project or downloaded from the
public node package manager (NPM) \cite{rdn-naive-bayes}. This CLI tool simply wraps the core Naive Bayes Classifier
with some scripting logic to process downloaded datasets of varying formats, described in \ref{subsection:datasets}.

\subsection{Training the Classifier}
\label{subsection:training}
Much of the work for Naive Bayes Classification takes place when training, rather than when classifying. True to this,
most of the business logic in this project resides in the \texttt{train} method, where a custom data structure is used,
making it easy to keep track of counters for (1) the total number of tokens seen, (2) the number of tokens seen for each
class, (3) the number of each token seen, and (4) the number of each token seen for each class. Using these counts,
the math is simple to find our prior and conditional probabilities when classifying.

\subsection{Classifying}
\label{subsection:classifying}
Classifying for Naive Bayes is simply a comparison of the Naive Bayes probability that a text blob belongs in each of
the known classes. The Naive Bayes simplification is that the presence of a token in a class is independent of any
other tokens found in the text blob. The formula for finding the probability a text blob belongs to a given class is
shown below. The derivation of this formula is well-known, for example see Leung's slides \cite{naive-bayes-slides}.

\begin{equation}
P(class)*\prod_{i=1}^{numTokens} P(token_i | class)
\end{equation}

One complexity with the formula is the matter of how to handle tokens you've never seen for the given
class (\begin{math}P(token_i | class)\end{math}). Algorithmically, the probability is 0, but this results in a
probability of 0 for every class when a document has a never-before-seen token. A simplification used in the
implementation presented here is to apply a \texttt{fudgeFactor} probability to these unknown tokens, such as 0.1.
This prevents new tokens from destroying our probabilities, without letting them influence a particular class too much
in the case where it has been seen in other classes.

\subsection{Tokenizing}
\label{subsection:tokenizing}
As with most Machine Learning techniques, the success of a Naive Bayes Classifier on text largely depends on what steps
are taken to normalize and slim the data before learning on it. In the case of Naive Bayes applied to learning text
blobs, the normalization and slimming step is determined by how the text blob is tokenized. By default, the classifier
implemented in this project simply splits the text by spaces, however the classifier can take an arbitrary tokenizer
function. This allows consumers to do application-specific tokenizing, such as lemmatization, or bi/tri-gramming, and
top-K word selection. Specific techniques attempted are described in \ref{subsection:advancedResults}.

\subsection{CLI Tool}
\label{subsection:cliTool}

\begin{table}
    \begin{tabular}{lll}
        \hline
        \textbf{Option} & \textbf{Value} & \textbf{Description} \\ [0.5ex]
        \hline\hline
        --help (-h) & [bool] & Print usage \\
        --verbose (-v) & [bool] & Print debug messages \\
        --csv & [bool] & Results in CSV format \\
        --tsv & [bool] & Results in TSV (Tabs) format for pasting into GDrive \\
        --inline (-I) & [bool] & Indicates --in is a file where each line has structure: "class ...text..." \\
        --in (-i) & <path/to/dir & Location to read text from \\
        --ratio (-r) & <1-100> & What percentage of dataset to use as Training data \\
        --number (-n) & <number> & How many iterations to run at the given options \\
        --precision (-p) & <decimalPlaces> & How many decimal places to include on performance results \\
        \hline
    \end{tabular}
    \caption{Parameters available in the Naive Bayes Classifier CLI Tool at the time of this paper}
    \label{table:cliParams}
\end{table}

To simplify interactions with the Naive Bayes Classifier, a CLI tool was developed for the purpose of easily tweaking
parameters on the classifier, evaluating arbitrary datasets, and calculating \& formatting performance results.

As with the classifier, the CLI tool was developed in Node.js for rapid prototyping and ease of interfacing with the
classifier. It parses user-specified parameters in order to evaluate the Naive Bayes Classifier on arbitrary datasets.
The CLI parameters are described in \ref{table:cliParams}.
